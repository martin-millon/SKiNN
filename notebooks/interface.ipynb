{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'NN_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_DEVICE_ORDER\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCI_BUS_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNN_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, random_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'NN_models'"
     ]
    }
   ],
   "source": [
    "#This notebook is used to test the NN_model\n",
    "#to get this notebook to work, have to manually set modul_path and scalers_path to be correct\n",
    "#for the package which should work automatically, see instead SKiNN_package_example.ipynb\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/local/home/lbiggio/lensing_odyssey_kinematics/SKiNN/src'))\n",
    "scalers_path = os.path.abspath(os.path.join('/local/home/lbiggio/lensing_odissey_kinematics/SKiNN/scalers/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if scalers_path not in sys.path:\n",
    "    sys.path.append(scalers_path)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "from NN_models import*\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/local/home/lbiggio/lensing_odyssey_kinematics/SKiNN/weights/upsampling_cosmo_gen_norm_1channel_new-epoch=1109-valid_loss=0.00.ckpt'\n",
    "\n",
    "\n",
    "model=Generator_imp()\n",
    "net = model.load_from_checkpoint(weights_path).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx = np.load('epfldata/parameters_new.npy')\n",
    "#trainy = np.load('epfldata/vrms_map_new.npy')\n",
    "\n",
    "#scaling_y = np.load('../scalers/scaler_y.npy')\n",
    "#scaling_x = joblib.load('../scalers/scaler_x')\n",
    "\n",
    "\n",
    "trainx = np.load('/local/home/lbiggio/lensing_odyssey_kinematics/data/parameters1.npy')\n",
    "trainy = np.load('/local/home/lbiggio/lensing_odyssey_kinematics/data/maps1.npy')\n",
    "testx = np.load('/local/home/lbiggio/lensing_odyssey_kinematics/data/parameters2.npy')\n",
    "testy = np.load('/local/home/lbiggio/lensing_odyssey_kinematics/data/maps2.npy')\n",
    "\n",
    "testy=testy/trainy.max()\n",
    "trainy=trainy/trainy.max()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaler = min_max_scaler.fit(trainx)\n",
    "testx = min_max_scaler.transform(testx)\n",
    "trainx = min_max_scaler.transform(trainx)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(trainx),torch.Tensor(trainy))\n",
    "test = TensorDataset(torch.Tensor(testx),torch.Tensor(testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_maps(net,scaling_x,scaling_y,input_p, plot=True):\n",
    "    \"\"\"Generate velocity maps given input parameters.\n",
    "    \n",
    "    net: neural network object\n",
    "    scaling_x: input scaler\n",
    "    scaling_y: output scaling\n",
    "    input_p: input parameters\n",
    "    plt: plot if True\n",
    "    \n",
    "    Returns the velocity maps \n",
    "    \"\"\"\n",
    "    \n",
    "    input_p = scaling_x.transform(np.reshape(input_p,(-1,len(input_p))))\n",
    "    input_p = torch.Tensor(input_p).cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = net(input_p.unsqueeze(0)).cpu().numpy()\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(24, 6))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(pred[0,:,:].squeeze())\n",
    "        plt.title('Prediction')\n",
    "        plt.colorbar()\n",
    "    \n",
    "    return pred*scaling_y #### rotation\n",
    "\n",
    "\n",
    "\n",
    "def generate_maps_no_scaling(net,input_p):\n",
    "    \"\"\"Generate velocity maps given input parameters.\n",
    "    \n",
    "    net: neural network object\n",
    "    scaling_x: input scaler\n",
    "    scaling_y: output scaling\n",
    "    input_p: input parameters\n",
    "    plt: plot if True\n",
    "    \n",
    "    Returns the velocity maps \n",
    "    \"\"\"\n",
    "    \n",
    "    input_p = torch.Tensor(input_p)\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = net(input_p.cuda()).cpu().numpy()\n",
    "    \n",
    "    return pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m example_input \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;241m0\u001b[39m][n,:]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput params: \u001b[39m\u001b[38;5;124m'\u001b[39m,example_input)\n",
      "File \u001b[0;32mmtrand.pyx:662\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": [
    "n = np.random.randint()\n",
    "example_input = test.tensors[0][n,:].unsqueeze(0)\n",
    "print('input params: ',example_input)\n",
    "#output = generate_maps(net,scaling_x,scaling_y,example_input, plot=True)\n",
    "plt.figure(figsize=(24, 6))\n",
    "pred = generate_maps_no_scaling(net,example_input, plot=True)\n",
    "plt.imshow(pred.numpy())\n",
    "\n",
    "#plt.figure()\n",
    "#test.tensors[1][n,:276,:276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#span = np.linspace(-0.4,0.6,100)\n",
    "#inp = example_input\n",
    "#for s in span:\n",
    "#    inp[-2] = s\n",
    "#    output = generate_maps(net,scaling_x,scaling_y,inp, plot=True)\n",
    "#    plt.title(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lenstro_kin_clean]",
   "language": "python",
   "name": "conda-env-lenstro_kin_clean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
